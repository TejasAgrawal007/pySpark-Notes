**ğŸ”¥ 50 Essential PySpark Transformation Functions**

### **1ï¸âƒ£ Basic Transformations**
1. `select(*cols)` â€“ Selects specific columns.
2. `filter(condition)` â€“ Filters rows based on condition (same as `where()`).
3. `where(condition)` â€“ Alias for `filter()`.
4. `distinct()` â€“ Removes duplicate rows.
5. `withColumn(colName, expression)` â€“ Creates or modifies a column.
6. `drop(*cols)` â€“ Drops specified columns.
7. `alias(newName)` â€“ Renames a column.
8. `limit(n)` â€“ Limits the number of rows.
9. `sample(fraction)` â€“ Returns a random sample of rows.
10. `orderBy(*cols)` â€“ Sorts rows based on specified columns.

### **2ï¸âƒ£ Aggregation & Grouping**
11. `groupBy(*cols).agg(aggregations)` â€“ Groups data and applies aggregate functions.
12. `count()` â€“ Counts number of rows.
13. `sum(column)` â€“ Calculates sum of a column.
14. `avg(column)` â€“ Calculates average of a column.
15. `min(column)` â€“ Finds minimum value in a column.
16. `max(column)` â€“ Finds maximum value in a column.
17. `mean(column)` â€“ Computes mean of a column.
18. `approxQuantile(column, probabilities, relativeError)` â€“ Computes approximate quantiles.
19. `cube(*cols).agg(aggregations)` â€“ Performs multi-dimensional grouping.
20. `rollup(*cols).agg(aggregations)` â€“ Creates hierarchical aggregation.

### **3ï¸âƒ£ Joins & Merging**
21. `join(df, on, how='inner')` â€“ Joins two DataFrames (`inner`, `left`, `right`, `full`).
22. `union(df)` â€“ Appends another DataFrame (same schema required).
23. `unionByName(df)` â€“ Appends another DataFrame (matching column names, not order).
24. `intersect(df)` â€“ Returns common rows between two DataFrames.
25. `subtract(df)` â€“ Returns rows that exist in one DF but not the other.
26. `crossJoin(df)` â€“ Returns cartesian product of two DataFrames.
27. `coalesce(numPartitions)` â€“ Reduces number of partitions.
28. `repartition(numPartitions)` â€“ Redistributes DataFrame into specified partitions.
29. `hint(name, *parameters)` â€“ Provides optimization hints for joins.
30. `cache()` â€“ Caches DataFrame in memory for faster access.

### **4ï¸âƒ£ Window Functions (Advanced Aggregation)**
31. `row_number().over(windowSpec)` â€“ Assigns a unique row number per partition.
32. `rank().over(windowSpec)` â€“ Assigns rank, allowing ties.
33. `dense_rank().over(windowSpec)` â€“ Assigns consecutive rank without skipping.
34. `ntile(n).over(windowSpec)` â€“ Divides dataset into `n` groups.
35. `lag(column, offset)` â€“ Retrieves previous row value.
36. `lead(column, offset)` â€“ Retrieves next row value.
37. `first(column).over(windowSpec)` â€“ Gets first value in a partition.
38. `last(column).over(windowSpec)` â€“ Gets last value in a partition.
39. `cume_dist().over(windowSpec)` â€“ Calculates cumulative distribution.
40. `percent_rank().over(windowSpec)` â€“ Computes percentile rank.

### **5ï¸âƒ£ String & Data Handling**
41. `cast(newType)` â€“ Changes column data type.
42. `substr(column, start, length)` â€“ Extracts a substring.
43. `split(column, delimiter)` â€“ Splits a string into an array.
44. `concat_ws(delimiter, *cols)` â€“ Concatenates multiple columns into one string.
45. `explode(column)` â€“ Converts array-type column into multiple rows.
46. `fillna(value, subset)` â€“ Fills null values with a specified value.
47. `replace(to_replace, value)` â€“ Replaces values in a column.
48. `regexp_replace(column, pattern, replacement)` â€“ Replaces substrings using regex.
49. `translate(column, matching, replace)` â€“ Replaces characters in a string.
50. `date_format(column, format)` â€“ Formats date columns into custom formats.

ğŸ’¡ **These are only transformations** â€“ they don't modify the original DataFrame but return a **new** transformed DataFrame.

